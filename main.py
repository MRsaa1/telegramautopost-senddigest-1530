#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import asyncio
from datetime import datetime, timezone
from zoneinfo import ZoneInfo
import feedparser
import re
from difflib import SequenceMatcher
from telegram import Bot
from typing import List, Dict, Optional
from openai import AsyncOpenAI
import html
import json
import hashlib
import contextlib
import math
from io import BytesIO
import aiohttp
from PIL import Image

# ================== CONFIG ==================
class Config:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
    TELEGRAM_CHANNEL_RU = "-1002597393191"

    # –î–ª–∏–Ω—ã
    MIN_LEN = 900
    MAX_LEN = 1000
    TG_HARD_LIMIT = 4000               # –æ–±—â–∏–π –ª–∏–º–∏—Ç Telegram
    TG_PHOTO_CAPTION_LIMIT = 1024      # –ª–∏–º–∏—Ç –ø–æ–¥–ø–∏—Å–∏ –∫ —Ñ–æ—Ç–æ

    # LLM
    LLM_CONCURRENCY = 3
    LLM_INPUT_CHARS = 320
    LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o")
    LLM_TEMP = float(os.getenv("LLM_TEMP", "0.45"))  # —á—É—Ç—å –∂–∏–≤–µ–µ –¥–ª—è –ª—ë–≥–∫–æ–≥–æ —é–º–æ—Ä–∞

    # –ö–µ—à
    CACHE_FILE = "rewrite_cache.json"

    # –°–≤–µ–∂–µ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–µ–π
    LOCAL_TZ = ZoneInfo("Europe/Vienna")
    FRESHNESS_HOURS = int(os.getenv("FRESHNESS_HOURS", "19"))
    SOFT_DECAY_POWER = 1.1  # —à—Ç—Ä–∞—Ñ –≤–æ–∑—Ä–∞—Å—Ç–∞ –≤ —Å–∫–æ—Ä–∏–Ω–≥–µ

    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    TARGET_IMAGE_HEIGHT = int(os.getenv("TARGET_IMAGE_HEIGHT", "750"))

    # –§–∏–¥—ã
    CRYPTO_FEEDS = [
        "https://cointelegraph.com/rss",
        "https://www.coindesk.com/arc/outboundfeeds/rss/",
        "https://decrypt.co/feed",
    ]
    FINANCE_FEEDS = [
        "https://www.bloomberg.com/feed/podcast/etf-report.xml",
        "https://feeds.a.dj.com/rss/RSSMarketsMain.xml",
        "https://www.reuters.com/finance/rss",
        "https://www.marketwatch.com/rss/topstories",
        "https://www.cnbc.com/id/15839135/device/rss/rss.html",
        "https://www.investing.com/rss/news_301.rss",
        "https://www.investing.com/rss/news_25.rss",
        "https://www.morningbrew.com/feed.xml",
    ]

# ================== UTIL ==================
def html_escape(s: str) -> str:
    s = s or ""
    s = s.replace("&", "&amp;")
    s = s.replace("<", "&lt;").replace(">", "&gt;")
    return s

def needs_link(text: str) -> bool:
    """–î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –æ–±—â–∏–π/–ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–Ω—ã–π"""
    if not re.search(
        r"(\d+|%|\$|‚Çø|Œû|bitcoin|btc|eth|google|fed|—Ä—ã–Ω–æ–∫|–∫–æ–º–ø–∞–Ω–∏—è|usd|eur|—Ñ—Ä—Å|–µ—Ü–±|–±–∏—Ä–∂–∞|—Ä–æ—Å—Ç|–ø–∞–¥–µ–Ω–∏|—Å—Ç–∞–≤–∫|–∏–Ω—Ñ–ª—è—Ü)",
        text,
        re.IGNORECASE,
    ):
        return True
    return False

def similar(a: str, b: str) -> float:
    return SequenceMatcher(None, a.lower().strip(), b.lower().strip()).ratio()

def normalize_title(t: str) -> str:
    t = re.sub(r"<.*?>", "", t or "")
    t = re.sub(r"[\[\]\(\){}‚Äú‚Äù\"'¬´¬ª‚Ä¢¬∑\-‚Äì‚Äî:;,.!?]", " ", t)
    t = re.sub(r"\s+", " ", t).strip().lower()
    return t

def sha_key(*parts: str) -> str:
    h = hashlib.sha256()
    for p in parts:
        h.update((p or "").encode("utf-8"))
        h.update(b"\x00")
    return h.hexdigest()

def best_entry_time(entry) -> Optional[datetime]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç datetime (UTC) –∏–∑ published_parsed –∏–ª–∏ updated_parsed.
    """
    st = entry.get("published_parsed") or entry.get("updated_parsed")
    if not st:
        return None
    try:
        dt = datetime(*st[:6], tzinfo=timezone.utc)
        return dt
    except Exception:
        return None

def should_add_wit(text: str) -> bool:
    """
    ~10% –ª—ë–≥–∫–æ–≥–æ —é–º–æ—Ä–∞: –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ –æ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ.
    """
    h = hashlib.sha1((text or "").encode("utf-8")).hexdigest()
    return (int(h[:2], 16) % 10) == 0  # 1 –∏–∑ 10

# ================== CACHED STORAGE ==================
class DiskCache:
    def __init__(self, path: str):
        self.path = path
        self._data = {}
        self._load()

    def _load(self):
        with contextlib.suppress(Exception):
            with open(self.path, "r", encoding="utf-8") as f:
                self._data = json.load(f)

    def save(self):
        with contextlib.suppress(Exception):
            with open(self.path, "w", encoding="utf-8") as f:
                json.dump(self._data, f, ensure_ascii=False, indent=2)

    def get(self, key: str) -> Optional[str]:
        return self._data.get(key)

    def set(self, key: str, value: str):
        self._data[key] = value

# ================== NEWS PROCESSOR ==================
class NewsProcessor:
    @staticmethod
    def add_emoji_flair(text: str) -> str:
        emoji_map = {
            r"(?i)–±–∏—Ç–∫–æ–∏–Ω|bitcoin|btc": "‚Çø",
            r"(?i)—ç—Ñ–∏—Ä|ethereum|eth": "Œû",
            r"(?i)–±—ã–∫|bull": "üêÇ",
            r"(?i)–º–µ–¥–≤–µ–¥—å|bear": "üêª",
            r"(?i)—Ä—ã–Ω–æ–∫|market": "üìà",
            r"(?i)—Ñ—Ä—Å|fed|–µ—Ü–±|ecb": "üè¶",
        }
        out = text
        for pattern, emoji in emoji_map.items():
            out = re.sub(pattern, f"{emoji} \\g<0>", out)
        return out

# ================== SCORING ==================
def score_news_item(item: Dict, all_news: List[Dict]) -> int:
    score = 0
    text = (item["title"] + " " + item["summary"]).lower()

    # –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    if any(
        kw in text
        for kw in [
            "–±–∏—Ç–∫–æ–∏–Ω","bitcoin","btc","ethereum","eth","—Ñ—Ä—Å","fed","treasury",
            "—Ä—ã–Ω–æ–∫","—Å—Ç–∞–≤–∫–∞","cpi","–∏–Ω—Ñ–ª—è—Ü–∏—è","—Ü–µ–Ω—Ç—Ä–æ–±–∞–Ω–∫","ecb","eps","–≤—ã—Ä—É—á–∫–∞",
            "–ø—Ä–∏–±—ã–ª—å","gdp","pmi"
        ]
    ):
        score += 10

    # —Ü–∏—Ñ—Ä—ã/–ø—Ä–æ—Ü–µ–Ω—Ç—ã/–≤–∞–ª—é—Ç–∞
    if re.search(r"(\d+%|\$\d+|\d+\.\d+)", text):
        score += 5

    # –∏—Å—Ç–æ—á–Ω–∏–∫
    source_url = item.get("source", "").lower()
    if any(src in source_url for src in ["bloomberg", "reuters", "cnbc", "coindesk", "cointelegraph"]):
        score += 7
    elif any(src in source_url for src in ["marketwatch", "investing"]):
        score += 5
    elif "morningbrew" in source_url:
        score += 2

    # —Å–≤–µ–∂–µ—Å—Ç—å (—ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ)
    if item.get("published_dt"):
        age_hours = (datetime.now(timezone.utc) - item["published_dt"]).total_seconds() / 3600
        score -= int(math.floor(age_hours ** Config.SOFT_DECAY_POWER))
    else:
        score -= 24  # –±–µ–∑ –¥–∞—Ç—ã ‚Äî –¥–∞–ª–µ–∫–æ –≤–Ω–∏–∑

    # —Ü–∏—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å (–ø–æ—Ö–æ–∂–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏)
    for other in all_news:
        if other is item:
            continue
        if similar(item["title_norm"], other["title_norm"]) > 0.7:
            score += 5
            break

    return score

# ================== FETCH NEWS ==================
async def fetch_news(feeds: List[str], max_news: int = 30) -> List[Dict]:
    entries = []
    for url in feeds:
        try:
            d = feedparser.parse(url)
            for entry in d.entries[:max_news]:
                published_dt = best_entry_time(entry)
                if published_dt is None:
                    continue
                age_hours = (datetime.now(timezone.utc) - published_dt).total_seconds() / 3600
                if age_hours > Config.FRESHNESS_HOURS:
                    continue  # –∂—ë—Å—Ç–∫–∏–π –æ—Ç—Å–µ–≤

                title = re.sub(r"<.*?>", "", (entry.get("title") or "").strip())
                summary = re.sub(r"<.*?>", "", (entry.get("summary") or "").strip())
                entries.append(
                    {
                        "title": title,
                        "title_norm": normalize_title(title),
                        "summary": summary,
                        "link": (entry.get("link") or "").strip(),
                        "published": entry.get("published_parsed"),
                        "published_dt": published_dt,  # aware UTC
                        "source": url,
                    }
                )
        except Exception as e:
            print(f"‚ö†Ô∏è Feed error ({url}): {str(e)[:100]}...")

    # –¥–µ–¥—É–ø –ø–æ —Å—Å—ã–ª–∫–µ
    seen = set()
    uniq = []
    for e in entries:
        if e["link"] and e["link"] not in seen:
            seen.add(e["link"])
            uniq.append(e)

    # —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    filtered = []
    for e in uniq:
        if any(similar(e["title_norm"], x["title_norm"]) > 0.92 for x in filtered):
            continue
        filtered.append(e)

    return filtered

# ================== OPENAI (REWRITER) ==================
client = AsyncOpenAI(api_key=Config.OPENAI_API_KEY)
_cache = DiskCache(Config.CACHE_FILE)
_sema = asyncio.Semaphore(Config.LLM_CONCURRENCY)

SYSTEM_MSG = (
    "–¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π —Ä–µ–¥–∞–∫—Ç–æ—Ä —É—Ä–æ–≤–Ω—è Bloomberg/NYT: —Å—Ç—Ä–æ–≥–æ –ø–æ —Ñ–∞–∫—Ç–∞–º, —á—ë—Ç–∫–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è, "
    "–¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π —Ç–æ–Ω –±–µ–∑ –∫–∞–Ω—Ü–µ–ª—è—Ä–∏—Ç–∞. –†—É—Å—Å–∫–∏–π —è–∑—ã–∫. "
    "–°–º—ã—Å–ª ‚Äî –ø–µ—Ä–≤–∏—á–µ–Ω, —Ü–∏—Ñ—Ä—ã/–ø—Ä–æ—Ü–µ–Ω—Ç—ã/—Å—É–º–º—ã –Ω–µ —Ç–µ—Ä—è—Ç—å."
)

def _build_prompt(text: str, allow_wit: bool) -> str:
    wit_rules = (
        "- –õ—ë–≥–∫–∏–π, –¥–µ–ª–∏–∫–∞—Ç–Ω—ã–π —à—Ç—Ä–∏—Ö –∏—Ä–æ–Ω–∏–∏ –¥–æ–ø—É—Å—Ç–∏–º, –Ω–æ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–æ—Ä–æ—Ç–∫–∏–π –ø—Ä–∏—ë–º –∏ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —É–º–µ—Å—Ç–Ω–æ—Å—Ç–∏.\n"
        "- –ï—Å–ª–∏ –∏—Ä–æ–Ω–∏—è –Ω–µ—É–º–µ—Å—Ç–Ω–∞ ‚Äî –Ω–µ –¥–æ–±–∞–≤–ª—è–π –µ—ë –≤–æ–≤—Å–µ.\n"
    ) if allow_wit else "- –ë–µ–∑ –∫–∞–∫–æ–≥–æ-–ª–∏–±–æ —é–º–æ—Ä–∞ –∏–ª–∏ –º–µ—Ç–∞—Ñ–æ—Ä.\n"

    return (
        "–ü–µ—Ä–µ–ø–∏—à–∏ –Ω–æ–≤–æ—Å—Ç—å –¥–ª—è —Ç–µ–ª–µ–≥—Ä–∞–º-–¥–∞–π–¥–∂–µ—Å—Ç–∞.\n"
        "- –§–æ—Ä–º–∞—Ç: –æ–¥–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, ‚âà12‚Äì18 —Å–ª–æ–≤.\n"
        "- –°—Ç–∏–ª—å: Bloomberg/NYT ‚Äî —Ñ–∞–∫—Ç—ã, —è—Å–Ω–æ –∏ —Å–¥–µ—Ä–∂–∞–Ω–Ω–æ; —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π, –±–µ–∑ –≤–æ–¥—ã.\n"
        f"{wit_rules}"
        "- –°–æ—Ö—Ä–∞–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ —Ü–∏—Ñ—Ä—ã/–ø—Ä–æ—Ü–µ–Ω—Ç—ã/—Å—É–º–º—ã/—Ç–∏–∫–µ—Ä—ã.\n"
        "- –ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ –∏ –∫–ª–∏—à–µ. –ë–µ–∑ —ç–º–æ–¥–∑–∏.\n\n"
        f"–û—Ä–∏–≥–∏–Ω–∞–ª: {text}"
    )

async def _rewrite_one(text: str) -> str:
    trimmed = text.strip()
    if len(trimmed) > Config.LLM_INPUT_CHARS:
        trimmed = trimmed[:Config.LLM_INPUT_CHARS].rsplit(" ", 1)[0] + "‚Ä¶"

    allow_wit = should_add_wit(trimmed)  # ~10% –∫–µ–π—Å–æ–≤
    prompt = _build_prompt(trimmed, allow_wit)

    key = sha_key(Config.LLM_MODEL, SYSTEM_MSG, prompt)
    cached = _cache.get(key)
    if cached:
        return cached

    # –±—ã—Å—Ç—Ä—ã–π —Ñ–æ–ª–±—ç–∫, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —É–∂–µ –∫–æ—Ä–æ—Ç–∫–∏–π —Å —Ü–∏—Ñ—Ä–∞–º–∏
    if len(trimmed.split()) <= 14 and re.search(r"[\d$%]", trimmed):
        _cache.set(key, trimmed)
        return trimmed

    async with _sema:
        for attempt in range(3):
            try:
                resp = await client.chat.completions.create(
                    model=Config.LLM_MODEL,
                    messages=[
                        {"role": "system", "content": SYSTEM_MSG},
                        {"role": "user", "content": prompt},
                    ],
                    temperature=Config.LLM_TEMP,
                    max_tokens=48,
                )
                out = (resp.choices[0].message.content or "").strip()
                _cache.set(key, out)
                return out
            except Exception:
                await asyncio.sleep(0.6 * (attempt + 1))

        _cache.set(key, trimmed)
        return trimmed

async def ai_rewrite_batch(bases: List[str]) -> List[str]:
    tasks = [asyncio.create_task(_rewrite_one(b)) for b in bases]
    results = await asyncio.gather(*tasks)
    _cache.save()
    return results

# ================== IMAGE (–∫–∞–∫ –≤ —Ç–≤–æ—ë–º –≤—Ç–æ—Ä–æ–º —Å–∫—Ä–∏–ø—Ç–µ) ==================
def _resize_image_height(buf: BytesIO, target_height: int) -> BytesIO:
    try:
        img = Image.open(buf)
        w, h = img.size
        if h <= target_height:
            buf.seek(0)
            return buf
        resized = img.resize((w, target_height), Image.Resampling.LANCZOS)
        out = BytesIO()
        resized.save(out, format="PNG")
        out.seek(0)
        return out
    except Exception:
        buf.seek(0)
        return buf

async def ai_generate_image(prompt: str) -> BytesIO:
    """
    DALL¬∑E 3, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–ª–æ—Å–∫–∞—è –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—è, –±–µ–∑ —Ç–µ–∫—Å—Ç–∞.
    –ò—Ç–æ–≥: –≤—ã—Å–æ—Ç–∞ —Å–∂–∞—Ç–∞ –¥–æ TARGET_IMAGE_HEIGHT, —à–∏—Ä–∏–Ω–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    """
    img_prompt = (
        f"Digital illustration for a finance/crypto daily digest: '{prompt}'. "
        "Fun but professional, modern flat style, soft colors, no text."
    )
    resp = await client.images.generate(
        model="dall-e-3",
        prompt=img_prompt,
        n=1,
        size="1024x1024",
    )
    img_url = resp.data[0].url
    async with aiohttp.ClientSession() as session:
        async with session.get(img_url) as r:
            r.raise_for_status()
            buf = BytesIO(await r.read())
    buf = _resize_image_height(buf, Config.TARGET_IMAGE_HEIGHT)
    return buf

def build_image_prompt_from_news(items: List[Dict]) -> str:
    titles = [re.sub(r"\s+", " ", i["title"]).strip() for i in items[:3] if i.get("title")]
    return " | ".join(titles) if titles else "Markets and crypto today"

# ================== BUILD CAPTION ==================
def enforce_fin_quota(selected: List[Dict], ranked: List[Dict], min_fin: int = 2) -> List[Dict]:
    fin = [n for n in ranked if n["source"] in Config.FINANCE_FEEDS]
    current_fin = [n for n in selected if n in fin]
    need = max(0, min_fin - len(current_fin))
    if need == 0:
        return selected

    to_add = []
    for n in ranked:
        if n in fin and n not in selected:
            to_add.append(n)
            if len(to_add) >= need:
                break

    # –≤—ã—Ç–µ—Å–Ω—è–µ–º –∫—Ä–∏–ø—Ç–æ –∏–∑ –∫–æ–Ω—Ü–∞
    for add in to_add:
        idx = None
        for i in range(len(selected) - 1, -1, -1):
            if selected[i]["source"] in Config.CRYPTO_FEEDS:
                idx = i
                break
        if idx is not None:
            selected[idx] = add
        else:
            selected.append(add)
    return selected

def assemble_caption(header: str, blocks: List[str], footer: str,
                     target_min: int, target_max: int) -> str:
    def join(h, bl, f):
        body = ("\n\n").join(bl)
        parts = [h.strip()]
        if body:
            parts += ["", body]
        if f:
            parts += ["", f]
        return "\n".join(parts)

    used = []
    for b in blocks:
        trial = join(header, used + [b], footer)
        if len(trial) <= target_max or len(trial) < target_min:
            used.append(b)
        else:
            break

    caption = join(header, used, footer)

    i = len(used)
    while len(caption) < target_min and i < len(blocks):
        trial = join(header, used + [blocks[i]], footer)
        if len(trial) <= target_max:
            used.append(blocks[i])
            caption = trial
            i += 1
        else:
            break

    if len(caption) < target_min and used:
        deficit = target_min - len(caption)
        used[-1] = used[-1] + (" " * min(deficit, 30))
        caption = join(header, used, footer)

    if len(caption) > target_max and used:
        base = join(header, used[:-1], footer)
        allowance = target_max - len(base) - 1
        if allowance > 20:
            used[-1] = used[-1][:allowance].rstrip() + "‚Ä¶"
            caption = join(header, used, footer)
        else:
            used = used[:-1]
            caption = join(header, used, footer)

    hard_cap = min(Config.TG_HARD_LIMIT, Config.TG_PHOTO_CAPTION_LIMIT)
    if len(caption) > hard_cap:
        caption = caption[: hard_cap - 1] + "‚Ä¶"

    print(f"üìä –ò—Ç–æ–≥: {len(caption)} —Å–∏–º–≤–æ–ª–æ–≤ (—Ü–µ–ª—å {target_min}-{target_max}, hard {hard_cap})")
    return caption

# ================== MAIN ==================
async def send_daily_digest():
    now_local = datetime.now(Config.LOCAL_TZ)
    print(f"üöÄ Building 15:30 digest‚Ä¶ Local time: {now_local:%Y-%m-%d %H:%M%z}")

    # 1) –ü—É–ª –Ω–æ–≤–æ—Å—Ç–µ–π
    crypto_pool = await fetch_news(Config.CRYPTO_FEEDS, 30)
    finance_pool = await fetch_news(Config.FINANCE_FEEDS, 30)
    all_news = crypto_pool + finance_pool

    if not all_news:
        print("‚ö†Ô∏è No news found within freshness window.")
        return

    # 2) –°–∫–æ—Ä–∏–Ω–≥ + —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞
    for item in all_news:
        item["score"] = score_news_item(item, all_news)
    all_news.sort(
        key=lambda x: (x["score"], x.get("published_dt") or datetime.min.replace(tzinfo=timezone.utc)),
        reverse=True,
    )

    # 3) –ë–∞–ª–∞–Ω—Å 70/30 –∏–∑ —Ç–æ–ø-12 –∏ –º–∏–Ω–∏–º—É–º 2 —Ñ–∏–Ω–Ω–æ–≤–æ—Å—Ç–∏
    top = all_news[:12]
    crypto_top = [n for n in top if n["source"] in Config.CRYPTO_FEEDS]
    finance_top = [n for n in top if n["source"] in Config.FINANCE_FEEDS]

    total_target = min(12, len(top))
    crypto_target = int(total_target * 0.7)
    finance_target = total_target - crypto_target

    prelim = crypto_top[:crypto_target] + finance_top[:finance_target]
    selected = enforce_fin_quota(prelim, top, min_fin=2)

    # 4) –ë–∞–∑—ã –¥–ª—è –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä–æ–≤–∫–∏
    bases: List[str] = []
    for item in selected:
        first_sentence = (item["summary"] or "").split(".")[0]
        base = f"{item['title']}. {first_sentence}".strip()
        bases.append(base)

    # 5) –ü–µ—Ä–µ–ø–∏—Å–∞—Ç—å LLM
    rewrites = await ai_rewrite_batch(bases)

    # 6) –°–±–æ—Ä–∫–∞ –±–ª–æ–∫–æ–≤
    blocks = []
    for item, rewritten in zip(selected, rewrites):
        pretty = NewsProcessor.add_emoji_flair(rewritten)  # —ç–º–æ–¥–∑–∏ —Ç–æ–ª—å–∫–æ –∑–¥–µ—Å—å
        safe = html_escape(pretty)
        if needs_link(pretty):
            block = f"üè∑Ô∏è {safe}\n<a href='{html.escape(item['link'], quote=True)}'>–ò—Å—Ç–æ—á–Ω–∏–∫</a>"
        else:
            block = f"üè∑Ô∏è {safe}"
        blocks.append(block)

    # 7) –ó–∞–≥–æ–ª–æ–≤–æ–∫/–ø–æ–¥–≤–∞–ª
    header = f"üìä –î–Ω–µ–≤–Ω–æ–π –¥–∞–π–¥–∂–µ—Å—Ç ‚Äî {now_local.strftime('%d.%m.%Y')}"
    footer = "–° –≤–∞–º–∏ –±—ã–ª ReserveOne ‚òïÔ∏è"

    # 8) –ü–æ–¥–ø–∏—Å—å
    caption = assemble_caption(header, blocks, footer, target_min=Config.MIN_LEN, target_max=Config.MAX_LEN)
    print(f"üßæ –°–∏–º–≤–æ–ª–æ–≤ –≤ –ø–æ–¥–ø–∏—Å–∏: {len(caption)}")

    # 9) –ö–∞—Ä—Ç–∏–Ω–∫–∞ (—Ç–æ—Ç –∂–µ —Å—Ç–∏–ª—å/—Ä–∞–∑–º–µ—Ä)
    img_prompt = build_image_prompt_from_news(selected)
    image = None
    try:
        image = await ai_generate_image(img_prompt)
    except Exception as e:
        print(f"‚ö†Ô∏è Image generation failed: {e}")

    # 10) –û—Ç–ø—Ä–∞–≤–∫–∞
    bot = Bot(token=Config.TELEGRAM_TOKEN)
    if image is not None:
        await bot.send_photo(
            chat_id=Config.TELEGRAM_CHANNEL_RU,
            photo=image,
            caption=caption[: Config.TG_PHOTO_CAPTION_LIMIT],
            parse_mode="HTML",
        )
    else:
        await bot.send_message(
            chat_id=Config.TELEGRAM_CHANNEL_RU,
            text=caption,
            parse_mode="HTML",
            disable_web_page_preview=False,
        )

    # 11) –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à–∞ (–æ—Ü–µ–Ω–æ—á–Ω–æ)
    hits = misses = 0
    for b in bases:
        trimmed = (b[:Config.LLM_INPUT_CHARS].rsplit(" ", 1)[0] + "‚Ä¶") if len(b) > Config.LLM_INPUT_CHARS else b
        key = sha_key(Config.LLM_MODEL, SYSTEM_MSG, _build_prompt(trimmed, should_add_wit(trimmed)))
        if _cache.get(key):
            hits += 1
        else:
            misses += 1
    print(f"‚úÖ Digest sent. Cache ~ hits: {hits}, misses: {misses}")

if __name__ == "__main__":
    asyncio.run(send_daily_digest())
